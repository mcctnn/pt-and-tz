{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enflasyon tahmini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yönlendirme\n",
    "I. <b>Import Libraries and Data Loading</b><br>\n",
    "a) [Import Libraries and Data Loading](#libraries)<br><br>\n",
    "\n",
    "II. <b> Data Understanding</b><br>\n",
    "a) [Macroeconomic Trends](#trend)<br>\n",
    "b) [Core CPI trend by Month and Quarter](#mq)<br><br>\n",
    "\n",
    "III. <b> Forecast</b><br>\n",
    "a) [ARIMA](#arima)<br>\n",
    "b) [Univariate Forecasting with LSTM](#ulstm)<br>\n",
    "c) [Multivariate Forecasting with LSTM](#mlstm)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import Libraries and Data Loading\n",
    "<a id=\"libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Gerçek değerler (y_true) ile tahmin edilen değerler (y_pred) arasındaki\n",
    "    ortalama kare hata (Mean Squared Error) hesaplar.\n",
    "    \n",
    "    Args:\n",
    "    y_true (array-like): Gerçek değerler\n",
    "    y_pred (array-like): Tahmin edilen değerler\n",
    "    \n",
    "    Returns:\n",
    "    float: Ortalama kare hata (MSE)\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "np.random.seed(234)\n",
    "tf.random.set_seed(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:53.405579Z",
     "iopub.status.busy": "2022-01-09T06:00:53.405287Z",
     "iopub.status.idle": "2022-01-09T06:00:53.411893Z",
     "shell.execute_reply": "2022-01-09T06:00:53.411106Z",
     "shell.execute_reply.started": "2022-01-09T06:00:53.405547Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:53.413543Z",
     "iopub.status.busy": "2022-01-09T06:00:53.413265Z",
     "iopub.status.idle": "2022-01-09T06:00:53.434914Z",
     "shell.execute_reply": "2022-01-09T06:00:53.434333Z",
     "shell.execute_reply.started": "2022-01-09T06:00:53.413512Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_raw = pd.read_csv('C:/Users/cetin/Desktop/macro_monthly1.csv',parse_dates=True)\n",
    "monthly_raw.shape\n",
    "monthly_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nan değerlerin drop edilip verilen tam olduğu kısım ele alınır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:53.436930Z",
     "iopub.status.busy": "2022-01-09T06:00:53.436327Z",
     "iopub.status.idle": "2022-01-09T06:00:53.458158Z",
     "shell.execute_reply": "2022-01-09T06:00:53.457483Z",
     "shell.execute_reply.started": "2022-01-09T06:00:53.436897Z"
    }
   },
   "outputs": [],
   "source": [
    "##monthly_raw.dropna(inplace=True)\n",
    "monthly_raw.fillna(0, inplace=True)\n",
    "monthly_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "Veri tiplerini hızlı bir şekilde kontrol etme ve gerçek zamanlı başlangıç ​​ve tarihi tarih-zamana dönüştürme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:53.459841Z",
     "iopub.status.busy": "2022-01-09T06:00:53.459358Z",
     "iopub.status.idle": "2022-01-09T06:00:53.475210Z",
     "shell.execute_reply": "2022-01-09T06:00:53.474534Z",
     "shell.execute_reply.started": "2022-01-09T06:00:53.459801Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_raw.dtypes\n",
    "\n",
    "monthly_raw.DATE = pd.to_datetime(monthly_raw.DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setindeki ay/yıl sayısını kontrol etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:53.477295Z",
     "iopub.status.busy": "2022-01-09T06:00:53.476484Z",
     "iopub.status.idle": "2022-01-09T06:00:53.484202Z",
     "shell.execute_reply": "2022-01-09T06:00:53.483439Z",
     "shell.execute_reply.started": "2022-01-09T06:00:53.477248Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_raw['DATE'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kopyasını oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:53.485864Z",
     "iopub.status.busy": "2022-01-09T06:00:53.485298Z",
     "iopub.status.idle": "2022-01-09T06:00:53.494010Z",
     "shell.execute_reply": "2022-01-09T06:00:53.493322Z",
     "shell.execute_reply.started": "2022-01-09T06:00:53.485828Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_df = monthly_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macroeconomic Indicator Trend\n",
    "<a id = \"trend\"></a>\n",
    "Öncelikle özellik oluşturma işlemini gerçekleştirip, Ay-Ay ve Yıl-Yıl bazında yüzdelik değişim yaratabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:53.495772Z",
     "iopub.status.busy": "2022-01-09T06:00:53.494998Z",
     "iopub.status.idle": "2022-01-09T06:00:55.627062Z",
     "shell.execute_reply": "2022-01-09T06:00:55.626192Z",
     "shell.execute_reply.started": "2022-01-09T06:00:53.495733Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_df['cpi_pct_mom'] = round((monthly_df['ccpi'].pct_change().fillna(0))*100,2)\n",
    "monthly_df['cpi_pct_yoy'] = round((monthly_df['ccpi'].pct_change(12).fillna(0))*100,2)\n",
    "\n",
    "monthly_df.iloc[:, 1:13].plot(kind ='line',\n",
    "            subplots = True,\n",
    "            figsize = (16,16),\n",
    "            title = ['Unemployment Rate', 'Personal Saving Rate','M2','Disposable Income','Personal Consumption Expenditure','Real Effective Exchange Rate',\n",
    "                     '10Y Treasury Yield','Fed Rate','Construction Spending','Industrial Production Index','Core CPI','Core CPI % Change MoM'],\n",
    "            legend = False,\n",
    "            layout = (4,3),\n",
    "            sharex = True,\n",
    "            style = ['midnightblue', 'steelblue', 'dodgerblue', 'slateblue','mediumblue','darkslateblue','red','salmon','brown','maroon','tomato'])\n",
    "\n",
    "plt.suptitle('43 Year Macroeconomic Indicators for the United States', fontsize = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core CPI trend by Month and Quarter\n",
    "<a id = \"mq\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:55.628414Z",
     "iopub.status.busy": "2022-01-09T06:00:55.628205Z",
     "iopub.status.idle": "2022-01-09T06:00:55.642695Z",
     "shell.execute_reply": "2022-01-09T06:00:55.641715Z",
     "shell.execute_reply.started": "2022-01-09T06:00:55.628386Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_df['year'] = monthly_df['DATE'].apply(lambda x: x.year)\n",
    "monthly_df['quarter'] = monthly_df['DATE'].apply(lambda x: x.quarter)\n",
    "monthly_df['month'] = monthly_df['DATE'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:55.647779Z",
     "iopub.status.busy": "2022-01-09T06:00:55.647245Z",
     "iopub.status.idle": "2022-01-09T06:00:55.733720Z",
     "shell.execute_reply": "2022-01-09T06:00:55.732897Z",
     "shell.execute_reply.started": "2022-01-09T06:00:55.647701Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.box(monthly_df[12:], x=\"month\", y=\"cpi_pct_yoy\", points = \"all\", template = \"presentation\",)\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',))\n",
    "\n",
    "fig = px.box(monthly_df[12:], x=\"quarter\", y=\"cpi_pct_yoy\", points = \"all\", template = \"presentation\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yıllık bazda Çekirdek CPI değişimine baktığımızda, yılın erken dönemlerinde Çekirdek CPI'da daha belirgin artışlar olduğunu görebiliriz. Son birkaç ayda ise daha fazla aykırı değer (alt bıyıkların altında) var, yani bir önceki yıla göre çok az değişiklik gösterdiler.<br> Çekirdek CPI'daki değişimin oynaklığını daha fazla inceleyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:55.735204Z",
     "iopub.status.busy": "2022-01-09T06:00:55.734960Z",
     "iopub.status.idle": "2022-01-09T06:00:55.873175Z",
     "shell.execute_reply": "2022-01-09T06:00:55.872356Z",
     "shell.execute_reply.started": "2022-01-09T06:00:55.735173Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    data_frame=monthly_df.groupby(['month']).std().reset_index(), \n",
    "    x=\"month\", \n",
    "    y=\"cpi_pct_yoy\", text=\"cpi_pct_yoy\"\n",
    ").update_traces(texttemplate='%{text:0.3f}', textposition='outside').update_xaxes(nticks=13)\n",
    "fig.show()\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame=monthly_df.groupby(['quarter']).std().reset_index(), \n",
    "    x=\"quarter\", \n",
    "    y=\"cpi_pct_yoy\", text=\"cpi_pct_yoy\").update_traces(texttemplate='%{text:0.3f}', textposition='outside').update_xaxes(nticks=5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:55.874720Z",
     "iopub.status.busy": "2022-01-09T06:00:55.874457Z",
     "iopub.status.idle": "2022-01-09T06:00:55.896546Z",
     "shell.execute_reply": "2022-01-09T06:00:55.896016Z",
     "shell.execute_reply.started": "2022-01-09T06:00:55.874689Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_raw.shape\n",
    "monthly_raw.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarihi veri çerçevesinin indeksi olarak ayarlama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:55.897888Z",
     "iopub.status.busy": "2022-01-09T06:00:55.897438Z",
     "iopub.status.idle": "2022-01-09T06:00:55.903253Z",
     "shell.execute_reply": "2022-01-09T06:00:55.902463Z",
     "shell.execute_reply.started": "2022-01-09T06:00:55.897851Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cpi = monthly_raw.set_index('DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Uygulaması\n",
    "<a id = \"arima\"></a>\n",
    "Sorun bir zaman serisi tahmini olduğundan, AR ve MA modellerini birleştiren Otoregresif Entegre Hareketli Ortalama (ARIMA) gelecekteki eğilimleri/değerleri tahmin etmek için kullanılabilir.<br> ARIMA'nın bazı avantajları arasında yorumlanabilirliği, uygulama kolaylığı ve hatta gözlem sayısının daha sofistike modeller uygulamak için yeterli olmadığı bu durum gibi nispeten kısa seriler için daha iyi çalışması sayılabilir.<br> Öte yandan, ARIMA modellerinin bir sınırlaması sabit varyans varsayımıdır ve finansal zaman serilerinde çoğu veri oynaklık, asimetriler, düzensiz zaman aralıkları, ani salgınlar gösterir, bu nedenle bu model genellikle finansal zaman serisi verilerinde zayıf performans gösterir (Petrica ve diğerleri, 2016).\n",
    "\n",
    "**Referanslar**:<br>\n",
    "- <a src=\"https://www.datasciencecentral.com/profiles/blogs/arima-sarima-vs-lstm-with-ensemble-learning-insights-for-time-ser\"> ARIMA/SARIMA vs LSTM with Ensemble learning Insights for Time Series Data by Sharmistha Chatterjee\n",
    "- Petrica ve diğerleri tarafından finansal ve parasal ekonomide ARIMA modellerinin sınırlandırılması, (2016)\n",
    "\n",
    "### Zaman Serisi Ayrıştırma\n",
    "Verileri trend, mevsimsel ve kalıntı bileşenlerine ayırın"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:55.905032Z",
     "iopub.status.busy": "2022-01-09T06:00:55.904644Z",
     "iopub.status.idle": "2022-01-09T06:00:56.911711Z",
     "shell.execute_reply": "2022-01-09T06:00:56.910730Z",
     "shell.execute_reply.started": "2022-01-09T06:00:55.904990Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cpi['ccpi'].plot()\n",
    "fig = seasonal_decompose(df_cpi['ccpi'], model='additive').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriler belirgin bir yükseliş eğilimi gösteriyor ve durağan değil. ARIMA modelinin temel varsayımlarından biri zaman serisinin durağan olması olduğundan, durağan olmayan durumu daha sonra düzeltmemiz gerekiyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verileri Bölme\n",
    "Veri kümesi küçük olduğundan, <b>örneklem dışı test veri kümesi olarak son 12 ayı</b> kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:56.913684Z",
     "iopub.status.busy": "2022-01-09T06:00:56.913274Z",
     "iopub.status.idle": "2022-01-09T06:00:57.176320Z",
     "shell.execute_reply": "2022-01-09T06:00:57.175455Z",
     "shell.execute_reply.started": "2022-01-09T06:00:56.913622Z"
    }
   },
   "outputs": [],
   "source": [
    "split_point = len(df_cpi) - 48\n",
    "train, test = df_cpi[0:split_point], df_cpi[split_point:]\n",
    "print('Training dataset: %d, Test dataset: %d' % (len(train), len(test)))\n",
    "train['ccpi'].plot()\n",
    "test['ccpi'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafikten, 2020'nin pandemi kısıtlamaları nedeniyle düşüş gösterdiğini görebiliyoruz. Turuncu çizgi Test setini gösteriyor.\n",
    "\n",
    "### İlk farkları alın\n",
    "Burada, zaman serisinin durağan olması için birim kökü kaldırmak için en uygun fark sayısını buluyoruz. Bu, diff() fonksiyonu kullanılarak ve Augmented Dickey-Fuller testi ile test edilerek yapılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:57.178334Z",
     "iopub.status.busy": "2022-01-09T06:00:57.178028Z",
     "iopub.status.idle": "2022-01-09T06:00:57.409618Z",
     "shell.execute_reply": "2022-01-09T06:00:57.409079Z",
     "shell.execute_reply.started": "2022-01-09T06:00:57.178294Z"
    }
   },
   "outputs": [],
   "source": [
    "diff = train['ccpi'].diff()\n",
    "plt.plot(diff)\n",
    "plt.show()\n",
    "diff = diff.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artırılmış Dickey–Fuller testi\n",
    "Küçük p değeriyle, 1 fark alma, birim kökü kaldırmak ve seriyi durağan hale getirmek için yeterlidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:57.411195Z",
     "iopub.status.busy": "2022-01-09T06:00:57.410821Z",
     "iopub.status.idle": "2022-01-09T06:00:57.430002Z",
     "shell.execute_reply": "2022-01-09T06:00:57.429444Z",
     "shell.execute_reply.started": "2022-01-09T06:00:57.411155Z"
    }
   },
   "outputs": [],
   "source": [
    "def adf_test(df):\n",
    "    result = adfuller(df.values)\n",
    "    if result[1] > 0.05:\n",
    "        print(\"Series is not stationary\")\n",
    "    else:\n",
    "        print(\"Series is stationary\")\n",
    "\n",
    "adf_test(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACF ve PACF'yi plot\n",
    "Şimdi, acf ve pacf çizimini kullanarak optimum p ve q'yu bulmamız gerekiyor. Burada p gecikme sayısı ve q MA teriminin sırasıdır. <br><br>\n",
    "Oto Regresif Terimin (p) sırasını bulma\n",
    "- PACF gecikmesi 1 önemlidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:57.431552Z",
     "iopub.status.busy": "2022-01-09T06:00:57.431177Z",
     "iopub.status.idle": "2022-01-09T06:00:57.773923Z",
     "shell.execute_reply": "2022-01-09T06:00:57.773325Z",
     "shell.execute_reply.started": "2022-01-09T06:00:57.431512Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_pacf(diff.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hareketli Ortalama Teriminin (q) sırasını bulma<br>\n",
    "- q = 1 ve 2 önemlidir, q = 1 için muhafazakar bir yaklaşım deneyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:57.775575Z",
     "iopub.status.busy": "2022-01-09T06:00:57.774879Z",
     "iopub.status.idle": "2022-01-09T06:00:58.110888Z",
     "shell.execute_reply": "2022-01-09T06:00:58.109720Z",
     "shell.execute_reply.started": "2022-01-09T06:00:57.775544Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_acf(diff.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelin oluşturulması\n",
    "CPI üstel büyüme gösterdiğinden (varyans artar), modeli ln(CPI) üzerine kurarız, örneğin ham değerleri logaritmik değerlere dönüştürürüz.<br>\n",
    "Daha önce keşfedildiği gibi, ARIMA model parametreleri 1,1,1 olarak ayarlanacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:58.112989Z",
     "iopub.status.busy": "2022-01-09T06:00:58.112386Z",
     "iopub.status.idle": "2022-01-09T06:00:58.280612Z",
     "shell.execute_reply": "2022-01-09T06:00:58.279579Z",
     "shell.execute_reply.started": "2022-01-09T06:00:58.112941Z"
    }
   },
   "outputs": [],
   "source": [
    "arima_model = ARIMA(np.log(train['ccpi']), order = (1,1,1))\n",
    "\n",
    "arima_fit = arima_model.fit()\n",
    "arima_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tahmini\n",
    "Sonraki 12 ay için tahmin (örneklem dışı 12 ay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:58.283086Z",
     "iopub.status.busy": "2022-01-09T06:00:58.282140Z",
     "iopub.status.idle": "2022-01-09T06:00:58.564548Z",
     "shell.execute_reply": "2022-01-09T06:00:58.563720Z",
     "shell.execute_reply.started": "2022-01-09T06:00:58.283040Z"
    }
   },
   "outputs": [],
   "source": [
    "forecast = arima_fit.forecast(steps=48)\n",
    "forecast = np.exp(forecast)\n",
    "\n",
    "plt.plot(forecast, color = 'red')\n",
    "\n",
    "pct_chg = ((forecast[-1] - df_cpi.iloc[-48]['ccpi'])/df_cpi.iloc[-48]['ccpi']) * 100\n",
    "print('The forecasted U.S. Core Consumer Price Index (CPI) YoY is ' , round(pct_chg,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA modelinin değerlendirilmesi\n",
    "- RMSE ve\n",
    "- Gözlemlenen y'nin ortalaması - tahmin edilen y\n",
    "\n",
    "Ortalama Hataya dayanarak, ARIMA modeli Çekirdek CPI değerini ortalama 0,25 oranında fazla tahmin eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:58.566095Z",
     "iopub.status.busy": "2022-01-09T06:00:58.565865Z",
     "iopub.status.idle": "2022-01-09T06:00:58.575341Z",
     "shell.execute_reply": "2022-01-09T06:00:58.573755Z",
     "shell.execute_reply.started": "2022-01-09T06:00:58.566066Z"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test['ccpi'].values, forecast[:48])\n",
    "print('MSE: ', mse)\n",
    "model_error = test['ccpi'] - forecast\n",
    "print('Mean Model Error: ', model_error.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eylül 2024 için 1 Adımlı Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:58.577133Z",
     "iopub.status.busy": "2022-01-09T06:00:58.576892Z",
     "iopub.status.idle": "2022-01-09T06:00:58.756775Z",
     "shell.execute_reply": "2022-01-09T06:00:58.755816Z",
     "shell.execute_reply.started": "2022-01-09T06:00:58.577104Z"
    }
   },
   "outputs": [],
   "source": [
    "arima_model = ARIMA(np.log(test['ccpi']), order = (1,1,1),freq=test.index.inferred_freq)\n",
    "\n",
    "arima_fit = arima_model.fit()\n",
    "\n",
    "forecast = arima_fit.forecast(steps=1)\n",
    "forecast = np.exp(forecast)\n",
    "\n",
    "print('The Core CPI value for the month September 2024 predicted by ARIMA model is', round(forecast[0],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genel olarak, ARIMA'nın 2024'in sonraki aylarında daha büyük bir artış olması nedeniyle kötü performans gösterdiğini görebiliyoruz. Diğer özellikleri ekleyerek ve çok değişkenli tahmin kullanarak modeli iyileştirebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM ile Tek Değişkenli Zaman Serisi Tahmini\n",
    "<a id = \"ulstm\"></a>\n",
    "Uzun Kısa Süreli Bellek (LSTM) Tekrarlayan Sinir Ağları, bilinmeyen süre gecikmeleri nedeniyle zaman serisi verilerine dayalı tahminler yapmakta popülerdir. LSTM, daha uzun zaman adımlarını hatırlamak için birden fazla anahtar kapısıyla kaybolan eğim sorununu ele alır. Bu nedenle modele gelen geçmiş girdiler bir ayak izi bırakır. LSTM'lerde, Hhidden Markov modelinde gerekli olduğu gibi önceden sonlu sayıda durum tutmaya gerek yoktur. LSTM'nin yaygın sınırlamaları (risk), aşırı uyum sağlamanın kolay olması ve bu modelleri hızlı bir şekilde eğitmek için çok fazla kaynak (hesaplama gücü) gerektirmesi ve bellek bant genişliğine bağlı hesaplama gerektirmesi anlamında eğitilmesinin zor olmasıdır.\n",
    "\n",
    "Sorun Ocak 2021'in Çekirdek CPI değerini tahmin etmeyi gerektirdiğinden, 12 giriş zaman adımını kullanarak tek adımlı bir tahmini tahmin etmek için LSTM'yi kullanabiliriz.\n",
    "\n",
    "LSTM mimarisi, varsayılan aktivasyon tanh'ına sahip bir gizli katmana sahip basit, sade bir LSTM olacaktır.\n",
    "\n",
    "**Referanslar**:<br>\n",
    "[RNN / LSTM'nin düşüşü](https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0) Eugenio Culurciello tarafından <br>\n",
    "[Derin Öğrenmenin Temelleri: Uzun Kısa Süreli Belleğe Giriş](https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ölçekleme ve Veri Hazırlama\n",
    "- Min-Maks Normalizasyonu ile Ölçekleme\n",
    "- Tek değişkenli diziyi 12 adım içeri 1 adım dışarı olacak şekilde örneklere bölme\n",
    "\n",
    "**Referanslar**<br>\n",
    "Bölünmüş dizi kodu, [buradan](https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/) erişilebilen Machine Learning Mastery koduna dayanmaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:58.759507Z",
     "iopub.status.busy": "2022-01-09T06:00:58.759041Z",
     "iopub.status.idle": "2022-01-09T06:00:58.769277Z",
     "shell.execute_reply": "2022-01-09T06:00:58.768404Z",
     "shell.execute_reply.started": "2022-01-09T06:00:58.759456Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ccpi = monthly_raw['ccpi'].values\n",
    "dataset = scaler.fit_transform(ccpi.reshape(-1,1))\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıda görüldüğü gibi 12 zaman adımlı ve 1 çıktı içeren bir veri yapısı oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:58.771988Z",
     "iopub.status.busy": "2022-01-09T06:00:58.771228Z",
     "iopub.status.idle": "2022-01-09T06:00:58.786423Z",
     "shell.execute_reply": "2022-01-09T06:00:58.785719Z",
     "shell.execute_reply.started": "2022-01-09T06:00:58.771907Z"
    }
   },
   "outputs": [],
   "source": [
    "n_steps_in = 12\n",
    "\n",
    "train, test = dataset[0:476], dataset[476:len(dataset),:]\n",
    "\n",
    "trainX, trainY = split_sequence(train, n_steps_in)\n",
    "testX, testY = split_sequence(test, n_steps_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeli Eğitme\n",
    "\n",
    "Tek katmanlı, bırakma düzenlemesi olmayan ve Erken Durdurma olmayan bir vanilya modeli oluşturun. Kullanılacak nöron sayısı, yüksek boyutluluk için 100'dür (böylece model eğilimleri yakalayabilir). Çoğu parametre ince ayar ve deneme-yanılma yaklaşımıyla seçilir.\n",
    "\n",
    "Katman sayısı, 1, sorunun karmaşıklığı nedeniyle seçilir. <br>Yapılan sinir ağının basit karmaşıklık yapısı (sadece 1 katman vardır ve bırakma eklemek önemli bilgilerin kaybolmasına neden olur) ve veri kümesi boyutu nedeniyle bırakma düzenlemesi yoktur. LSTM için optimum düzeylerde 0.1/0.2 bırakma düzenlemesi denendi ve test kümesindeki tahmin performansını önemli ölçüde azalttı. Bırakma, özellikle sınırlı zaman adımları ve 1 katman içeren bu sorunda önemli bağlam bilgilerini siler. Ayrıca, tren kaybı ve doğrulama kaybı aşırı uyum açısından dikkatlice izlenir.<br>\n",
    "Benzer şekilde, sinir ağının boyutu ve küçük veri boyutu nedeniyle 0,001'lik küçük bir öğrenme oranı kullanılır.\n",
    "\n",
    "Toplu boyut 100 dönem olarak ayarlanır. Toplu boyut ince ayarı, modelin performansının gözlemlenmesine dayanarak yapılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:00:58.789816Z",
     "iopub.status.busy": "2022-01-09T06:00:58.787737Z",
     "iopub.status.idle": "2022-01-09T06:02:41.044517Z",
     "shell.execute_reply": "2022-01-09T06:02:41.043697Z",
     "shell.execute_reply.started": "2022-01-09T06:00:58.789760Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = trainX.shape[2]\n",
    "\n",
    "uni_model = Sequential()\n",
    "\n",
    "# Adding the LSTM layer\n",
    "uni_model.add(LSTM(64, input_shape=(trainX.shape[1], n_features)))\n",
    "\n",
    "# Adding the output layer\n",
    "uni_model.add(Dense(1))\n",
    "\n",
    "uni_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = 'mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "fit = uni_model.fit(trainX, \n",
    "          trainY, validation_data = (testX, testY),   \n",
    "          epochs = 100, batch_size=1,\n",
    "          verbose = 0)\n",
    "\n",
    "\n",
    "# Check for overfitting\n",
    "plt.plot(fit.history['loss'], label = 'training', color = 'Blue')\n",
    "plt.plot(fit.history['val_loss'], label = 'validation', color = 'Red')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hafif bir aşırı uyum görebiliriz.\n",
    "\n",
    "**Not**: Doğrulama kaybı, geçirilen küçük batch_size nedeniyle önemli artış ve dalgalanmalar gösteriyor.\n",
    "\n",
    "### Test Setinde Tahminler\n",
    "- Hem eğitim setinde hem de test setinde tahminler yapın\n",
    "- Normalleştirilmişten orijinal değere ters dönüşüm yapın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:41.046847Z",
     "iopub.status.busy": "2022-01-09T06:02:41.045952Z",
     "iopub.status.idle": "2022-01-09T06:02:41.587397Z",
     "shell.execute_reply": "2022-01-09T06:02:41.586523Z",
     "shell.execute_reply.started": "2022-01-09T06:02:41.046805Z"
    }
   },
   "outputs": [],
   "source": [
    "trainPredict = uni_model.predict(trainX)\n",
    "testPredict = uni_model.predict(testX)\n",
    "\n",
    "Ytrain_hat = scaler.inverse_transform(trainPredict)\n",
    "Ytrain_actual = scaler.inverse_transform(trainY)\n",
    "Ytest_hat = scaler.inverse_transform(testPredict)\n",
    "Ytest_actual = scaler.inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tek değişkenli LSTM'yi değerlendirme\n",
    "\n",
    "ARIMA'ya benzer şekilde, modelin tahmin gücünü değerlendirmek için MSE ve Ortalama Model Hatası'nı kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:41.592182Z",
     "iopub.status.busy": "2022-01-09T06:02:41.591750Z",
     "iopub.status.idle": "2022-01-09T06:02:41.599912Z",
     "shell.execute_reply": "2022-01-09T06:02:41.599070Z",
     "shell.execute_reply.started": "2022-01-09T06:02:41.592149Z"
    }
   },
   "outputs": [],
   "source": [
    "trainScore = mean_squared_error(Ytrain_actual, Ytrain_hat[:,0])\n",
    "print('Train Score: %.2f MSE' % (trainScore))\n",
    "testScore = mean_squared_error(Ytest_actual, Ytest_hat[:,0])\n",
    "print('Test Score: %.2f MSE' % (testScore))\n",
    "\n",
    "model_error = Ytest_actual - Ytest_hat[:,0]\n",
    "print('Mean Model Error: ', model_error.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu model, 1.70 MSE ve 0.78 Ortalama Model Hatası ile ARIMA modeline kıyasla önemli bir gelişme gösterdi; bu da modelin hafif bir düşük tahmin verdiğini gösteriyor. MSE'ye göre, modelin ortalama hatası sqrt(1.70) = 1.30'dur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:41.601732Z",
     "iopub.status.busy": "2022-01-09T06:02:41.601324Z",
     "iopub.status.idle": "2022-01-09T06:02:42.054292Z",
     "shell.execute_reply": "2022-01-09T06:02:42.053714Z",
     "shell.execute_reply.started": "2022-01-09T06:02:41.601702Z"
    }
   },
   "outputs": [],
   "source": [
    "observed = df_cpi.loc['2020-11-01':'2024-08-01',['ccpi']]\n",
    "observed.plot(color = 'SteelBlue', title = 'Actual', legend = False)\n",
    "plt.show()\n",
    "\n",
    "predicted = pd.DataFrame(Ytest_hat, index=pd.date_range('2020-11-01',periods=len(Ytest_hat),freq='M'))\n",
    "predicted.plot(color = 'Firebrick', title = 'Forecasted', legend = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıdaki çizgi grafiğinden, tek değişkenli LSTM'nin Çekirdek CPI'nin şeklini \"yaklaşık olarak\" tahmin edebildiğini (geri kalmış olsa da) ve değeri hafife aldığını görebiliriz.\n",
    "\n",
    "### Eylül 2024 için Tahmin\n",
    "\n",
    "Modele son 12 gözlemi (12 adım içeri) girdik ve böylece Kasım 2021 ayı için Çekirdek CPI değeri olacak 1 adım dışarıyı tahmin etti.\n",
    "\n",
    "Ardından, yıllık yüzdelik değişimi manuel olarak hesapladık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:42.056141Z",
     "iopub.status.busy": "2022-01-09T06:02:42.055368Z",
     "iopub.status.idle": "2022-01-09T06:02:42.118743Z",
     "shell.execute_reply": "2022-01-09T06:02:42.117831Z",
     "shell.execute_reply.started": "2022-01-09T06:02:42.056104Z"
    }
   },
   "outputs": [],
   "source": [
    "x_input = np.array(dataset[-12:])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "\n",
    "forecast_normalized = uni_model.predict(x_input)\n",
    "\n",
    "forecast = scaler.inverse_transform(forecast_normalized)\n",
    "print('The Core CPI value for the month Sep 2024 predicted by LSTM is ', forecast[0][0])\n",
    "\n",
    "pct_chg = ((forecast[0][0] - df_cpi.iloc[-12]['ccpi'])/df_cpi.iloc[-12]['ccpi']) * 100\n",
    "print('The forecasted U.S. Core Consumer Price Index (CPI) YoY is ' , round(pct_chg,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM'lerle Çok Değişkenli Zaman Serisi Tahmini\n",
    "<a id = \"mlstm\"></a>\n",
    "### Veri Hazırlama\n",
    "- Granger Nedensellik Testi ile Özellik Seçimi\n",
    "- Min-Maks normalizasyonu ile Ölçekleme\n",
    "- Çok değişkenli diziyi 12 adımlı ve 1 adımlı örneklere bölme (<i>Kod machinelearningmastery'den referans alınmıştır</i>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Özellik Seçimi\n",
    "Çekirdek CPI'yi tahmin etmek için hangi özelliklerin yararlı olduğunu görmek için Granger Nedensellik testini kullanacağız.\n",
    "Bu testi kullanmadan önceki temel varsayımlardan biri, verilerin durağan olmasını gerektirir. Bu nedenle, her özellik için ilk farkları alır ve durağanlığı kontrol etmek için aynı ADF test fonksiyonunu kullanırız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:42.120373Z",
     "iopub.status.busy": "2022-01-09T06:02:42.119922Z",
     "iopub.status.idle": "2022-01-09T06:02:42.528443Z",
     "shell.execute_reply": "2022-01-09T06:02:42.527667Z",
     "shell.execute_reply.started": "2022-01-09T06:02:42.120340Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_df_stationary = df_cpi.diff().dropna()\n",
    "monthly_df_stationary = monthly_df_stationary.rename_axis('indicator', axis=1)\n",
    "fig = px.line(monthly_df_stationary.iloc[:,0:10], facet_col=\"indicator\", facet_col_wrap=1) \n",
    "fig.update_yaxes(visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:42.529926Z",
     "iopub.status.busy": "2022-01-09T06:02:42.529721Z",
     "iopub.status.idle": "2022-01-09T06:02:42.704689Z",
     "shell.execute_reply": "2022-01-09T06:02:42.703811Z",
     "shell.execute_reply.started": "2022-01-09T06:02:42.529900Z"
    }
   },
   "outputs": [],
   "source": [
    "for indi in monthly_df_stationary:\n",
    "    print('ADF Test: ', indi)\n",
    "    adf_test(monthly_df_stationary[[indi]])\n",
    "    \n",
    "monthly_df_stationary[['m2']] = monthly_df_stationary[['m2']].diff().dropna()\n",
    "monthly_df_stationary[['tcs']] = monthly_df_stationary[['tcs']].diff().dropna()\n",
    "monthly_df_stationary[['ccpi']] = monthly_df_stationary[['ccpi']].diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk fark alma işleminden sonra M2, TCS ve CCPI hala durağan olmadığından bu göstergeler için ikinci fark alma işlemini yaparak hala birim kök içerip içermediğine bakacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:42.706524Z",
     "iopub.status.busy": "2022-01-09T06:02:42.706230Z",
     "iopub.status.idle": "2022-01-09T06:02:42.872327Z",
     "shell.execute_reply": "2022-01-09T06:02:42.871388Z",
     "shell.execute_reply.started": "2022-01-09T06:02:42.706483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop any NaNs first\n",
    "monthly_df_stationary = monthly_df_stationary.dropna()\n",
    "\n",
    "for indi in monthly_df_stationary:\n",
    "    print('ADF Test: ', indi)\n",
    "    adf_test(monthly_df_stationary[[indi]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M2, TCS ve CCPI artık ikinci fark alma işleminden sonra durağandır. Özelliklerimiz ile Çekirdek CPI arasındaki nedenselliği araştırmak için Grangers Nedensellik Testi'ni kullanmaya devam edebiliriz. Granger nedenselliği, tahmine dayalı ve finansal ekonomide oldukça önemli olan istatistiksel bir nedensellik kavramıdır.\n",
    "\n",
    "Aşağıdaki kod [stackoverflow](https://stackoverflow.com/questions/58005681/is-it-possible-to-run-a-vector-autoregression-analysis-on-a-large-gdp-data-with) adresinden alınmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:42.874872Z",
     "iopub.status.busy": "2022-01-09T06:02:42.874627Z",
     "iopub.status.idle": "2022-01-09T06:02:47.433037Z",
     "shell.execute_reply": "2022-01-09T06:02:47.432475Z",
     "shell.execute_reply.started": "2022-01-09T06:02:42.874844Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlag=12\n",
    "test = 'ssr_chi2test'\n",
    "\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "   \n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "grangers_causation_matrix(monthly_df_stationary, variables = monthly_df_stationary.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada, sadece **son satıra** odaklanabiliriz ve daha önceki gibi 0,05'lik bir anlamlılık düzeyi kullanacağız, dolayısıyla 0,05'ten küçük olan tüm p değerleri için sıfır hipotezini reddedebilir ve özellik granger'ının Temel TÜFE'ye neden olduğu sonucuna varabiliriz.<br><br> Gerçek Efektif Döviz Kuru, 10 Yıllık Hazine Getirisi ve Fed Faiz Oranı anlamlı değildir, dolayısıyla öncelikle bunları gelecekteki modellerimizden hariç tutarak veri çerçevesinden çıkarabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.434423Z",
     "iopub.status.busy": "2022-01-09T06:02:47.434197Z",
     "iopub.status.idle": "2022-01-09T06:02:47.439893Z",
     "shell.execute_reply": "2022-01-09T06:02:47.438853Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.434394Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_df = df_cpi.drop(['reer', 'ir','ffer'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Maks Normalizasyonu ile Ölçekleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.441829Z",
     "iopub.status.busy": "2022-01-09T06:02:47.441464Z",
     "iopub.status.idle": "2022-01-09T06:02:47.456142Z",
     "shell.execute_reply": "2022-01-09T06:02:47.455437Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.441786Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled = scaler.fit_transform(feat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeniden kullanılabilirlik amaçları için diziyi veri çerçevesine geri dönüştürün"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.457894Z",
     "iopub.status.busy": "2022-01-09T06:02:47.457487Z",
     "iopub.status.idle": "2022-01-09T06:02:47.478073Z",
     "shell.execute_reply": "2022-01-09T06:02:47.477226Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.457852Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled, columns=feat_df.columns, index=feat_df.index)\n",
    "scaled_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Çok Değişkenli Dizileri Örneklere Bölme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.480007Z",
     "iopub.status.busy": "2022-01-09T06:02:47.479716Z",
     "iopub.status.idle": "2022-01-09T06:02:47.486826Z",
     "shell.execute_reply": "2022-01-09T06:02:47.486179Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.479967Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()    \n",
    "    for i in range(len(sequences)):\n",
    "        #find end of pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out - 1\n",
    "        \n",
    "        #check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        \n",
    "        #gather input and output\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix - 1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tek değişkenli modele benzer şekilde, son 12 ayı test kümesi olarak bırakacağız. Girişleri, eğitim kümesi için 1994'ten 2019'a (2000'in ilk 12 zaman adımını içereceği) ve test kümesi için 2019'dan 2020'ye (2019'un ilk 12 adımı içereceği) olacak şekilde yapılandırıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.488317Z",
     "iopub.status.busy": "2022-01-09T06:02:47.488103Z",
     "iopub.status.idle": "2022-01-09T06:02:47.535811Z",
     "shell.execute_reply": "2022-01-09T06:02:47.534963Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.488292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Eğitim verileri (1981-01-01 - 2020-11-01)\n",
    "in_cpi = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['ccpi']]) \n",
    "in_ur = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['unrate']])\n",
    "in_m2  = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['m2']])\n",
    "in_pce = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['pce']])\n",
    "in_dspic  = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['dspic']])\n",
    "in_tcs = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['tcs']])\n",
    "in_psr = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['psr']])\n",
    "in_ind = np.array(scaled_df.loc['1981-01-01':'2020-11-01', ['indpro']])\n",
    "\n",
    "# Test verileri (2020-11-01 - 2024-08-01, toplam 48 veri)\n",
    "test_cpi = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['ccpi']]) \n",
    "test_ur = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['unrate']])\n",
    "test_pce = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['pce']])\n",
    "test_dspic  = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['dspic']])\n",
    "test_m2  = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['m2']])\n",
    "test_tcs = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['tcs']])\n",
    "test_psr = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['psr']])\n",
    "test_ind = np.array(scaled_df.loc['2020-11-01':'2024-08-01', ['indpro']])\n",
    "\n",
    "# Output verileri\n",
    "trainoutput_cpi = in_cpi\n",
    "testoutput_cpi = test_cpi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daha sonra giriş ve çıkış verilerini satır, sütun formatına yeniden şekillendiriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.537200Z",
     "iopub.status.busy": "2022-01-09T06:02:47.536935Z",
     "iopub.status.idle": "2022-01-09T06:02:47.553133Z",
     "shell.execute_reply": "2022-01-09T06:02:47.552416Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.537170Z"
    }
   },
   "outputs": [],
   "source": [
    "in_cpi = in_cpi.reshape((len(in_cpi), 1))\n",
    "in_ur = in_ur.reshape((len(in_ur), 1))\n",
    "in_pce = in_pce.reshape((len(in_pce), 1))\n",
    "in_dspic = in_dspic.reshape((len(in_dspic), 1))\n",
    "in_m2  = in_m2.reshape((len(in_m2), 1))\n",
    "in_tcs = in_tcs.reshape((len(in_tcs), 1))\n",
    "in_psr = in_psr.reshape((len(in_psr), 1))\n",
    "in_ind = in_ind.reshape((len(in_ind), 1))\n",
    "\n",
    "test_cpi = test_cpi.reshape((len(test_cpi), 1))\n",
    "test_ur = test_ur.reshape((len(test_ur), 1))\n",
    "test_pce = test_pce.reshape((len(test_pce), 1))\n",
    "test_dspic = test_dspic.reshape((len(test_dspic), 1))\n",
    "test_m2  = test_m2.reshape((len(test_m2), 1))\n",
    "test_tcs = test_tcs.reshape((len(test_tcs), 1))\n",
    "test_psr = test_psr.reshape((len(test_psr), 1))\n",
    "test_ind = test_ind.reshape((len(test_ind), 1))\n",
    "\n",
    "trainoutput_cpi = trainoutput_cpi.reshape((len(trainoutput_cpi), 1))\n",
    "testoutput_cpi = testoutput_cpi.reshape((len(testoutput_cpi), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi, numpy hstack kullanarak tüm sütunları yatay olarak istifliyoruz ve onu split sequences fonksiyonuna geçirilmeye hazır hale getiriyoruz. Ve tanımlanmış adımları ve tek adımlı tahmini geçiriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.555181Z",
     "iopub.status.busy": "2022-01-09T06:02:47.554554Z",
     "iopub.status.idle": "2022-01-09T06:02:47.571012Z",
     "shell.execute_reply": "2022-01-09T06:02:47.570392Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.555146Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = np.hstack((in_cpi, in_ur, in_pce, in_dspic, in_m2, in_tcs, in_psr, in_ind, trainoutput_cpi))\n",
    "testset = np.hstack((test_cpi, test_ur, test_pce, test_dspic, test_m2, test_tcs, test_psr, test_ind, testoutput_cpi))\n",
    "\n",
    "n_steps_in = 12\n",
    "n_steps_out = 1\n",
    "\n",
    "trainX, trainy = split_sequences(trainset, n_steps_in, n_steps_out)\n",
    "\n",
    "testX, testy = split_sequences(testset, n_steps_in, n_steps_out)\n",
    "\n",
    "trainX.shape, trainy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelin Eğitimi\n",
    "İlk model, tek değişkenli modelle benzer parametrelere sahip bu çok değişkenli modelde denendi ancak düşük performansla sonuçlandı. Model, varsayılan 32 toplu boyutu ve ek bir LSTM katmanının istiflenmesiyle 500 döneme daha fazla ayarlandı. En uygun dönemleri ve toplu boyutu bulmak için daha önce bir GridSearchCV denemesi yapıldı.\n",
    "\n",
    "Model önemli ölçüde aşırı uyum gösterdi, bu nedenle EarlyStopping ve Dropout ile düzenleme kullanıldı. Son Dropout %20 olarak ayarlandı ve rec ile Dense tam çıktı katmanı arasına eklendi. EarlyStopping sabrı 50 olarak ayarlandı.\n",
    "\n",
    "Hiperparametreler ayrıca performansı gözlemleyen manuel deneysel çalışmalarla ayarlandı.\n",
    "\n",
    "**Referanslar**:<br>\n",
    "<li><a src=\"https://stackoverflow.com/questions/48714407/rnn-regularization-which-component-to-regularize/58868383#58868383\"> RNN Düzenlemesine kapsamlı bir cevap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:02:47.572090Z",
     "iopub.status.busy": "2022-01-09T06:02:47.571849Z",
     "iopub.status.idle": "2022-01-09T06:03:14.269757Z",
     "shell.execute_reply": "2022-01-09T06:03:14.268951Z",
     "shell.execute_reply.started": "2022-01-09T06:02:47.572061Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = trainX.shape[2]\n",
    "\n",
    "multi_model = Sequential()\n",
    "\n",
    "# Adding the LSTM layer and dropout regularizaiton\n",
    "multi_model.add(LSTM(100, return_sequences = True, input_shape=(n_steps_in, n_features)))\n",
    "multi_model.add(LSTM(100))\n",
    "multi_model.add(Dropout(0.2))\n",
    "\n",
    "# Adding output layer\n",
    "multi_model.add(Dense(n_steps_out))\n",
    "\n",
    "multi_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = 'mean_squared_error')\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', patience =50,\n",
    "                  mode = 'min',\n",
    "                  verbose = 0)\n",
    "\n",
    "fit = multi_model.fit(trainX, \n",
    "          trainy, validation_data = (testX, testy),   \n",
    "          epochs = 500, verbose=0, callbacks = [earlystop])\n",
    "\n",
    "\n",
    "# Check for overfitting\n",
    "plt.plot(fit.history['loss'], label = 'training', color = 'Blue')\n",
    "plt.plot(fit.history['val_loss'], label = 'validation', color = 'Red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not**: Model 170. döneme yakın bir zamanda erken durduruldu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Özellik Önemi\n",
    "\n",
    "Tekrarlayan sinir ağını etkileyen özellik önemini niceliksel olarak belirlemenin ve tanımlamanın birkaç yolu vardır. Bunlardan bazıları Pertubasyonlar, [Masking](https://stackoverflow.com/questions/44119207/is-there-any-way-to-get-variable-importance-with-keras)/[LIME](https://arxiv.org/abs/1606.05386), [Permutation Importance](https://www.kaggle.com/cdeotte/lstm-feature-importance) ve [SHAP](https://christophm.github.io/interpretable-ml-book/shap.html)'dir (ancak bu, benim tarafımda tensorflow 2.7.0 ile birçok uyumluluk sorununa yol açtı).\n",
    "\n",
    "Burada, Masking ve LIME'a oldukça benzeyen pertubasyon etkisini kullanacağız. Buradaki fikir, gürültüyü tanıtmayı/her değişkeni rastgele normal dağılımla bozmayı ve ardından bozulmuş tahmin edilen y ile orijinal tahmin edilen y arasındaki farkı hesaplamayı içerir.\n",
    "\n",
    "**Referanslar**<br>\n",
    "Sinir Ağları'ndaki bozulma hakkında daha fazla bilgi [burada](https://towardsdatascience.com/perturbation-theory-in-deep-neural-network-dnn-training-adb4c20cab1b) ve [burada](https://stats.stackexchange.com/questions/191855/variable-importance-in-rnn-or-lstm) bulunabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:03:14.271168Z",
     "iopub.status.busy": "2022-01-09T06:03:14.270955Z",
     "iopub.status.idle": "2022-01-09T06:03:16.664861Z",
     "shell.execute_reply": "2022-01-09T06:03:16.664004Z",
     "shell.execute_reply.started": "2022-01-09T06:03:14.271142Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importance(model, g):\n",
    "    random_ind = np.random.choice(g.shape[0], 100, replace=False) # Randomly generate 100 numbers arange(218) \n",
    "    x = g[random_ind] #  Take 100 random sample from training set\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(8):  # iterate over the 7 features\n",
    "        new_x = x.copy()\n",
    "        perturbation_in = np.random.normal(0.0, 0.7, size=new_x.shape[:2]) # Draw random samples from normal distribution with sd = 0.7, this value is arbitary and would not affect the order of effect as its just introducing noise.\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation_in\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5\n",
    "        print(f'Variable {i+1}, Perturbation Effect: {effect:.3f}')\n",
    "        \n",
    "feature_importance(multi_model,trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bozulma etkisi sonuçlarıyla, bu model/veri setinde Çekirdek CPI'yi tahmin etmek için önemli özelliklerin geçmiş **Çekirdek CPI**, **Kişisel Tüketim Harcaması** ve **M2** olduğunu söyleyebiliriz. Kişisel Tüketim en önemli özelliklerden biridir ve bu açıktır çünkü PCE enflasyonu belirlemede önemli bir ölçüttür, bu nedenle Çekirdek CPI ile yakından ilişkili olmalıdır.\n",
    "\n",
    "### Test Setinde Tahminler\n",
    "\n",
    "Tahmin sonrasında, min-max normalizasyonunu tersine çevirmemiz gerekir. Bunu yapmak için, verileri normalizasyondan önceki orijinal forma geri şekillendiririz.\n",
    "- testX'i yeniden şekillendirin ve doğru konumlarda y-hat (tahmin) ile birleştirin\n",
    "- testX'i yeniden şekillendirin ve doğru konumlarda gerçek y ile birleştirin\n",
    "\n",
    "Orijinal veri çerçevesinin sırasını eşleştirmek için, unemployment_rate, m2, pce, dspic, ffr, psr ve cpi sırasına göre birleştiririz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:03:16.673731Z",
     "iopub.status.busy": "2022-01-09T06:03:16.673317Z",
     "iopub.status.idle": "2022-01-09T06:03:16.738722Z",
     "shell.execute_reply": "2022-01-09T06:03:16.737913Z",
     "shell.execute_reply.started": "2022-01-09T06:03:16.673696Z"
    }
   },
   "outputs": [],
   "source": [
    "testPredict = multi_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:03:16.740249Z",
     "iopub.status.busy": "2022-01-09T06:03:16.740018Z",
     "iopub.status.idle": "2022-01-09T06:03:16.745974Z",
     "shell.execute_reply": "2022-01-09T06:03:16.744898Z",
     "shell.execute_reply.started": "2022-01-09T06:03:16.740218Z"
    }
   },
   "outputs": [],
   "source": [
    "testX = testX.reshape((testX.shape[0], testX.shape[2]*testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:03:16.748530Z",
     "iopub.status.busy": "2022-01-09T06:03:16.747311Z",
     "iopub.status.idle": "2022-01-09T06:03:16.756062Z",
     "shell.execute_reply": "2022-01-09T06:03:16.755517Z",
     "shell.execute_reply.started": "2022-01-09T06:03:16.748492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Invert scaling for Predicted\n",
    "testY_hat = np.concatenate((testX[:, 1:8], testPredict), axis=1)\n",
    "testY_hat = scaler.inverse_transform(testY_hat)\n",
    "\n",
    "testY_hat = testY_hat[:,7]\n",
    "\n",
    "# Invert scaling for Actual\n",
    "testY_actual = np.concatenate((testX[:,1:8], testy), axis=1)\n",
    "testY_actual = scaler.inverse_transform(testY_actual)\n",
    "\n",
    "testY_actual = testY_actual[:,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Çok değişkenli LSTM'yi değerlendirme\n",
    "\n",
    "Önceki modellere benzer şekilde, aynı metrikleri kullanacağız: MSE ve Ortalama Model Hatası."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:03:16.757555Z",
     "iopub.status.busy": "2022-01-09T06:03:16.757006Z",
     "iopub.status.idle": "2022-01-09T06:03:16.771319Z",
     "shell.execute_reply": "2022-01-09T06:03:16.770556Z",
     "shell.execute_reply.started": "2022-01-09T06:03:16.757522Z"
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(testY_actual, testY_hat)\n",
    "print('Test MSE: %.3f' % mse)\n",
    "\n",
    "model_error = testY_actual - testY_hat\n",
    "print('Mean Model Error: ', model_error.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testY_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T06:03:16.772794Z",
     "iopub.status.busy": "2022-01-09T06:03:16.772539Z",
     "iopub.status.idle": "2022-01-09T06:03:17.215189Z",
     "shell.execute_reply": "2022-01-09T06:03:17.214381Z",
     "shell.execute_reply.started": "2022-01-09T06:03:16.772754Z"
    }
   },
   "outputs": [],
   "source": [
    "observed = df_cpi.loc['2020-11-01':'2024-08-01',['ccpi']]\n",
    "observed.plot(color = 'SteelBlue', title = 'Actual', legend = False)\n",
    "plt.show()\n",
    "\n",
    "predicted = pd.DataFrame(testY_hat, index=pd.date_range('2020-11-01',periods=35,freq='M'))\n",
    "predicted.plot(color = 'Firebrick', title = 'Forecasted', legend = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tek değişkenli LSTM ile karşılaştırıldığında, model Ocak ayında kötü bir başlangıç ​​yaptı ve 2021'deki Çekirdek TÜFE'nin gerçek şeklini 'yaklaşık olarak' tahmin edemedi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eylül 2024 Tahmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array(scaled[-12:])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "\n",
    "forecast_normalized = multi_model.predict(x_input)\n",
    "# Manually inverse Min-max normalization\n",
    "max_cpi = df_cpi['ccpi'].max()\n",
    "min_cpi = df_cpi['ccpi'].min()\n",
    "forecast =  max_cpi-forecast_normalized[0][0]/(max_cpi-min_cpi)\n",
    "print('The Core CPI value for the month Sep 2024 predicted by LSTM is ', forecast)\n",
    "\n",
    "pct_chg = ((forecast - df_cpi.iloc[-12]['ccpi'])/df_cpi.iloc[-12]['ccpi']) * 100\n",
    "print('The forecasted U.S. Core Consumer Price Index (CPI) YoY is ' , round(pct_chg,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
